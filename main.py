import sys
import time
import difflib
import requests
from powerbi import (
    get_access_token,
    get_group_and_dataset_ids,
    refresh_dataset,
    get_refresh_history,
    get_group_id_by_name
)
from email_utils import send_email_log
from logger_utils import setup_logger

# Inicializa logger
logger, log_file_path = setup_logger()

# Solicita workspace (via argumento ou input)
if len(sys.argv) > 1:
    workspace_input = sys.argv[1].strip()
else:
    workspace_input = input("Digite o nome do workspace: ").strip()

if not workspace_input:
    logger.error("âŒ Nome do workspace nÃ£o informado.")
    sys.exit(1)

# Solicita nome do dataset (opcional)
if len(sys.argv) > 2:
    dataset_input = " ".join(sys.argv[2:]).strip()
else:
    dataset_input = input("Digite o nome do dataset (ou pressione Enter para atualizar todos): ").strip()

# Autentica
token = get_access_token()
if not token:
    logger.error("âŒ Falha ao obter token de acesso.")
    sys.exit(1)

# ObtÃ©m o ID do workspace
group_id = get_group_id_by_name(token, workspace_input)
logger.info(f"ğŸ“‚ Workspace '{workspace_input}' encontrado com ID: {group_id}")

# Lista todos os datasets do workspace via API
datasets_url = f"https://api.powerbi.com/v1.0/myorg/groups/{group_id}/datasets"
headers = {"Authorization": f"Bearer {token}"}
response = requests.get(datasets_url, headers=headers)

if response.status_code != 200:
    logger.error(f"âŒ Falha ao obter datasets. CÃ³digo {response.status_code}: {response.text}")
    sys.exit(1)

datasets_api = response.json().get("value", [])
all_datasets = {ds["name"]: ds["id"] for ds in datasets_api}
datasets_lower = {name.lower(): name for name in all_datasets.keys()}

# Define quais datasets atualizar
if dataset_input:
    key = dataset_input.lower()
    dataset_name = datasets_lower.get(key)

    if not dataset_name:
        sugestao = difflib.get_close_matches(dataset_input, all_datasets.keys(), n=1, cutoff=0.4)
        if sugestao:
            confirmar = input(f"âš ï¸ Dataset '{dataset_input}' nÃ£o encontrado. VocÃª quis dizer '{sugestao[0]}'? (s/n): ").strip().lower()
            if confirmar == "s":
                dataset_name = sugestao[0]
            else:
                logger.info("âŒ Cancelado pelo usuÃ¡rio.")
                sys.exit(0)
        else:
            logger.error("âŒ Nenhum dataset similar encontrado.")
            sys.exit(1)

    datasets_to_update = {dataset_name: all_datasets[dataset_name]}
else:
    logger.info("ğŸ” Nenhum nome informado â€” atualizando todos os datasets encontrados.")
    datasets_to_update = all_datasets

dataset_logs = []

# Loop de atualizaÃ§Ã£o
for dataset_name, dataset_id in datasets_to_update.items():
    logger.info(f"â¡ï¸ Atualizando dataset: {dataset_name}")
    try:
        status_code, result = refresh_dataset(group_id, dataset_id, token)
        logger.info(f"ğŸš€ AtualizaÃ§Ã£o solicitada (HTTP {status_code})")

        if status_code == 202:
            logger.info("â³ Aguardando conclusÃ£o da atualizaÃ§Ã£o...")
            while True:
                status, history = get_refresh_history(group_id, dataset_id, token)

                if status != 200:
                    logger.error(f"âŒ Erro ao consultar histÃ³rico: {history}")
                    break

                refresh = history.get("value", [])[0]
                refresh_status = refresh["status"]
                start_time = refresh["startTime"]
                end_time = refresh.get("endTime", "â³ Em andamento")

                logger.info(f"ğŸ•’ Status: {refresh_status} | InÃ­cio: {start_time}")

                if refresh_status in ["Completed", "Failed"]:
                    logger.info(f"ğŸ Finalizado: {refresh_status} | InÃ­cio: {start_time} | Fim: {end_time}\n")
                    dataset_logs.append({
                        "name": dataset_name,
                        "status": refresh_status,
                        "start": start_time,
                        "end": end_time
                    })
                    break
                else:
                    time.sleep(10)
        else:
            logger.warning(f"âš ï¸ AtualizaÃ§Ã£o nÃ£o aceita. Detalhes: {result}")
            dataset_logs.append({
                "name": dataset_name,
                "status": "Erro na solicitaÃ§Ã£o",
                "start": "-",
                "end": "-"
            })

    except Exception as e:
        logger.exception(f"âŒ Erro ao processar {dataset_name}: {e}")
        dataset_logs.append({
            "name": dataset_name,
            "status": f"Erro: {e}",
            "start": "-",
            "end": "-"
        })

# Envia e-mail com os logs
send_email_log(
    subject=f"AtualizaÃ§Ã£o de datasets | Workspace: {workspace_input}",
    dataset_logs=dataset_logs,
    sender_email="",
    receiver_email="cesargl@sebraesp.com.br",
    smtp_server="", smtp_port=0, smtp_user="", smtp_password="",
    attachment_path=log_file_path
)

logger.info("âœ… AtualizaÃ§Ãµes concluÃ­das e e-mail enviado.")
